{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Socrata Data Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "from configparser import ConfigParser"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Setting up domain of dataset and dataset identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup configuration\n",
    "config = ConfigParser()\n",
    "config.read('./config.ini')\n",
    "app_token = config['socrata']['APP_TOKEN']\n",
    "\n",
    "# Create client to Socrata\n",
    "client = Socrata(domain='data.cityofnewyork.us', app_token=app_token, timeout=60)\n",
    "\n",
    "# NYC 311 Calls (2010-Present)\n",
    "dataset = 'erm2-nwe9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query(dataset_identifier: str, query: str, return_df: bool=False) -> pd.DataFrame | list:\n",
    "    '''\n",
    "    Function to query Socrata 'data.cityofnewyork.us' domain.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_identifier: name of the dataset\n",
    "    query: SQL-like query string\n",
    "    return_df: Whether to return DataFrame (True) or list of results (False)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame or list of results\n",
    "    '''\n",
    "    results = client.get(dataset_identifier=dataset_identifier, query=query)\n",
    "    if return_df:\n",
    "        return pd.DataFrame.from_records(results)\n",
    "    else:\n",
    "        return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Pull\n",
    "Retrieving the initial dataset, converting datatypes, and writing to Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        unique_key,\n",
    "        created_date,\n",
    "        descriptor,\n",
    "        incident_zip,\n",
    "        community_board,\n",
    "        latitude,\n",
    "        longitude\n",
    "    WHERE\n",
    "        complaint_type = \"Dead Animal\"\n",
    "        AND incident_zip IS NOT NULL\n",
    "        AND community_board IS NOT NULL\n",
    "        AND latitude IS NOT NULL\n",
    "        AND longitude IS NOT NULL\n",
    "    ORDER BY\n",
    "        created_date DESC,\n",
    "        unique_key DESC\n",
    "    LIMIT\n",
    "        20000\n",
    "    \"\"\"\n",
    ")\n",
    "df = get_query(dataset_identifier=dataset, query=query, return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>community_board</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56555673</td>\n",
       "      <td>2023-01-18T01:56:13.000</td>\n",
       "      <td>Other</td>\n",
       "      <td>10312</td>\n",
       "      <td>03 STATEN ISLAND</td>\n",
       "      <td>40.543335225468695</td>\n",
       "      <td>-74.16427024861207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56550860</td>\n",
       "      <td>2023-01-17T23:48:41.000</td>\n",
       "      <td>Cat</td>\n",
       "      <td>11203</td>\n",
       "      <td>17 BROOKLYN</td>\n",
       "      <td>40.65485475476207</td>\n",
       "      <td>-73.9317147872499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56555712</td>\n",
       "      <td>2023-01-17T23:44:53.000</td>\n",
       "      <td>Rat or Mouse</td>\n",
       "      <td>11211</td>\n",
       "      <td>01 BROOKLYN</td>\n",
       "      <td>40.70211330551143</td>\n",
       "      <td>-73.95842710828077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_key             created_date    descriptor incident_zip  \\\n",
       "0   56555673  2023-01-18T01:56:13.000         Other        10312   \n",
       "1   56550860  2023-01-17T23:48:41.000           Cat        11203   \n",
       "2   56555712  2023-01-17T23:44:53.000  Rat or Mouse        11211   \n",
       "\n",
       "    community_board            latitude           longitude  \n",
       "0  03 STATEN ISLAND  40.543335225468695  -74.16427024861207  \n",
       "1       17 BROOKLYN   40.65485475476207   -73.9317147872499  \n",
       "2       01 BROOKLYN   40.70211330551143  -73.95842710828077  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Datetypes\n",
    "Converting dates to datetime and latitude/longitude to numeric (float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12182 entries, 0 to 12181\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   unique_key       12182 non-null  object\n",
      " 1   created_date     12182 non-null  object\n",
      " 2   descriptor       12182 non-null  object\n",
      " 3   incident_zip     12182 non-null  object\n",
      " 4   community_board  12182 non-null  object\n",
      " 5   latitude         12182 non-null  object\n",
      " 6   longitude        12182 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 666.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_datatypes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Convert created date to datetime object\n",
    "    df['created_date'] = pd.to_datetime(df['created_date'])\n",
    "\n",
    "    # Convert latitude and longitude to double\n",
    "    df['latitude'] = pd.to_numeric(df['latitude'])\n",
    "    df['longitude'] = pd.to_numeric(df['longitude'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_datatypes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12182 entries, 0 to 12181\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   unique_key       12182 non-null  object        \n",
      " 1   created_date     12182 non-null  datetime64[ns]\n",
      " 2   descriptor       12182 non-null  object        \n",
      " 3   incident_zip     12182 non-null  object        \n",
      " 4   community_board  12182 non-null  object        \n",
      " 5   latitude         12182 non-null  float64       \n",
      " 6   longitude        12182 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), object(4)\n",
      "memory usage: 666.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Parquet and JSON metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easy!\n",
    "df.to_parquet('./data/' + dataset + '.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_metadata(current_series: pd.Series, dataset_identifier: str) -> None:\n",
    "    temp = {\n",
    "        'last_date': current_series['created_date'].isoformat(),\n",
    "        'last_pull': datetime.now().isoformat()\n",
    "    }\n",
    "    date_obj = json.dumps(temp, indent=4)\n",
    "    filename = './data/' + dataset_identifier + '.metadata.json'\n",
    "    with open(filename, 'w') as outfile:\n",
    "        outfile.write(date_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_metadata(df.iloc[0], dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsequent Data Pulls\n",
    "After the initial data pull, metadata will determine if new 311 calls for dead animals have been made before rewriting a new Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metadata(dataset_identifier: str) -> str:\n",
    "    filename = './data/' + dataset_identifier + '.metadata.json'\n",
    "    with open(filename, 'r') as file:\n",
    "        metadict = json.load(file)\n",
    "    \n",
    "    return metadict['last_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_date = read_metadata(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-01-18T01:56:13'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_complaint_query = (\n",
    "    \"\"\"\n",
    "    SELECT created_date\n",
    "    WHERE\n",
    "        complaint_type = \"Dead Animal\"\n",
    "        AND incident_zip IS NOT NULL\n",
    "        AND community_board IS NOT NULL\n",
    "        AND latitude IS NOT NULL\n",
    "        AND longitude IS NOT NULL\n",
    "    ORDER BY\n",
    "        created_date DESC,\n",
    "        unique_key DESC\n",
    "    LIMIT 1\n",
    "    \"\"\"\n",
    ")\n",
    "lc_date = get_query(dataset, last_complaint_query)[0]['created_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-01-18T01:56:13.000'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_pull(metadata_date: str, last_complaint_date: str) -> bool:\n",
    "    md = datetime.fromisoformat(metadata_date)\n",
    "    ld = datetime.fromisoformat(last_complaint_date)\n",
    "\n",
    "    return True if md != ld else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "should_pull(md_date, lc_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible SQL injection but not front facing\n",
    "latest_query = (\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        unique_key,\n",
    "        created_date,\n",
    "        descriptor,\n",
    "        incident_zip,\n",
    "        community_board,\n",
    "        latitude,\n",
    "        longitude\n",
    "    WHERE\n",
    "        created_date > '{}'\n",
    "        AND complaint_type = \"Dead Animal\"\n",
    "        AND incident_zip IS NOT NULL\n",
    "        AND community_board IS NOT NULL\n",
    "        AND latitude IS NOT NULL\n",
    "        AND longitude IS NOT NULL\n",
    "    ORDER BY\n",
    "        created_date DESC,\n",
    "        unique_key DESC\n",
    "    LIMIT\n",
    "        20000\n",
    "    \"\"\".format(md_date)\n",
    ")\n",
    "latest = get_query(dataset, latest_query, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_query(dataset, latest_query)    # Should be empty list since notebook run on same day"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/19 16:51:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = spark.read.parquet('./data/' + dataset + '.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- unique_key: string (nullable = true)\n",
      " |-- created_date: timestamp (nullable = true)\n",
      " |-- descriptor: string (nullable = true)\n",
      " |-- incident_zip: string (nullable = true)\n",
      " |-- community_board: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n",
      "+----------+------------+----------+------------+---------------+----------+----------+\n",
      "|unique_key|created_date|descriptor|incident_zip|community_board|  latitude| longitude|\n",
      "+----------+------------+----------+------------+---------------+----------+----------+\n",
      "|  56555673|  2023-01...|     Other|       10312|     03 STAT...|40.5433...|-74.164...|\n",
      "|  56550860|  2023-01...|       Cat|       11203|     17 BROO...|40.6548...|-73.931...|\n",
      "|  56555712|  2023-01...|Rat or ...|       11211|     01 BROO...|40.7021...|-73.958...|\n",
      "|  56556160|  2023-01...|       Cat|       11215|     06 BROO...|40.6709...|-73.984...|\n",
      "|  56551816|  2023-01...|       Dog|       10465|       10 BRONX|40.8247...|-73.820...|\n",
      "+----------+------------+----------+------------+---------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.printSchema()\n",
    "new_df.show(n=5, truncate=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f0b6f135bc1705489a39fe037a4ea567380cc1aee42feb45ea593c263db1952"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
